# -*- coding: utf-8 -*-
"""Naive_Bayes_without_lib.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W7-jmTA7_0NlgBmV0JLF58RTWjHGrPfn
"""

#Importing all the packages for the execution of the code
import pandas as pd
import numpy as np
import collections
import itertools

df_balance= pd.read_csv("/content/drive/MyDrive/datasets/balance-scale.csv")
dict_test={}

df_balance=df_balance.replace('R','Positive')
df_balance=df_balance.replace('L','Negative')

df_training=df_balance.sample(frac=0.7)#spliting the data into traning and testing 

df_testing=pd.concat([df_balance, df_training, df_training]).drop_duplicates(keep=False)  
dict_test=df_testing['Class'].to_dict()
dict_uni_values=df_training.T.apply(lambda x: x.nunique(), axis=1).to_dict()#seeing all the unique values

from google.colab import drive
drive.mount('/content/drive')

list_uni_values=[]
for i in df_training['Class']:
    list_uni_values.append(i)
unique=set(list_uni_values) 

dict_prior={}
prior = df_training.groupby("Class").size().div(len(df_training))
dict_prior=prior.to_dict()#converting the probability df to dictionary
total_values_inclass={}
total_values_inclass = df_training.groupby("Class").size().to_dict()#calculating the total values in the class

value_count_columns={}
for column in df_training.columns:
    if column != "Class":
        sd=(df_training.groupby(column)["Class"].value_counts()+1).to_dict()
        value_count_columns[column]=sd

#doing m-estimate, its not required but putting it up
condition_prob={}
condition_prob_col={}
for key,value in value_count_columns.items():
    for key1,value1 in value.items():
        total=(value1/(total_values_inclass[key1[1]]+dict_uni_values[key]))
        condition_prob[key1]=total
    condition_prob_col.setdefault(key,{}).update(condition_prob)
print(condition_prob_col)

cloumn_indexing={}
prediction_labelling={}
predic_of_R={}
predic_of_L={}

column_list=["LWght","LDist","RWght","RDist"]

for x in column_list:
    col_dex=[df_testing.columns.get_loc(x)]
for x in column_list:
    cloumn_indexing[df_testing.columns.get_loc(x)]=x

for index,row in df_testing.iterrows():
    R_calculate=1
    L_calculate=1
    for columns in range(1,5):
    
        R_calculate=R_calculate*condition_prob_col[cloumn_indexing[columns]][(row[cloumn_indexing[columns]],'Positive')]
        L_calculate=L_calculate*condition_prob_col[cloumn_indexing[columns]][(row[cloumn_indexing[columns]],'Negative')]   
    
    predic_of_R=total_values_inclass['Positive']*R_calculate
    predic_of_L=total_values_inclass['Negative']*L_calculate
    
    label='Positive' if predic_of_R>predic_of_L else 'Negative'
    prediction_labelling[index]=label
print(prediction_labelling)

df_predicted=pd.DataFrame.from_dict(prediction_labelling,orient='index')
df_predicted.columns=["Predicted Label"]

TPC=0
TNC=0
FPC=0
FNC=0
for key in dict_test.keys():
    for key1 in prediction_labelling.keys():
        if key == key1:
            if dict_test[key] == 'Positive' and prediction_labelling[key] == dict_test[key]:
                TPC+=1
            elif dict_test[key] == 'Negative' and prediction_labelling[key] == dict_test[key]:
                TNC+=1
            elif dict_test[key] == 'Positive' and prediction_labelling[key] != dict_test[key]:
                FPC+=1
            elif dict_test[key] == 'Negative' and prediction_labelling[key] != dict_test[key]:    
                FNC+=1
#print(TPC,TNC,FPC,FNC)

Accuracy=(TPC+TNC)/(TPC+TNC+FPC+FNC)
print("Accuracy=",round(Accuracy*100,2),"% ")

